{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<h3 align=\"center\"> Capstone Project</h3>**\n",
    "## **<h3 align=\"center\"> Segmentation Analysis - Classification Problem </h3>**\n",
    "**Group members:**<br>\n",
    "Alexandra Pinto - 20211599@novaims.unl.pt - 20211599<br>\n",
    "Ilona Nacu - 20211602@novaims.unl.pt - 20211602<br>\n",
    "Francisco Farinha - 20211550@novaims.unl.pt - 20211550<br>\n",
    "João Barradas - 20211590@novaims.unl.pt - 20211590<br>\n",
    "Rafael Proença  - 2021681@novaims.unl.pt - 2021681<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "In this notebook we will use two datasets to have more info about costumers. Our goal is to do segmentation of our cluters. <br>\n",
    "For this, we decided to use one of the datasets that firstly we selected for doing the DataBase of movies. This dataset boasts numerous compelling features that we believe will significantly enhance the segmentation process. Rather than generating potentially unreliable or untruthful data, tapping into this existing dataset appears to be a more reliable and insightful approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    # Initialize an empty list to store the dataframes\\n    dfs = []\\n\\n    # Read CSV files from the ZIP file into separate DataFrames\\n    with zipfile.ZipFile(zip_path, \\'r\\') as zip_file:\\n        # Read specific movie CSV files\\n        with zip_file.open(\\'Data/Movie_files/archive (2)/rotten_tomatoes_movies.csv\\') as csv_file:\\n            rot_movies2 = pd.read_csv(io.TextIOWrapper(csv_file, \\'utf-8\\'))\\n\\n        with zip_file.open(\\'Data/Movie_files/archive (2)/rotten_tomatoes_movie_reviews.csv\\') as csv_file:\\n            rot_critic2 = pd.read_csv(io.TextIOWrapper(csv_file, \\'utf-8\\'))\\n            \\nexcept FileNotFoundError:\\n    print(\"File not found. Please provide the correct path to the ZIP file.\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_movies2 = pd.read_csv('Data/Movie_files/archive (2)/rotten_tomatoes_movies.csv')\n",
    "rot_critic2 = pd.read_csv('Data/Movie_files/archive (2)/rotten_tomatoes_movie_reviews.csv')\n",
    "\n",
    "'''\n",
    "!!! Os ficheiros antes estavam em zip, mas já nao estao. Pode se apagar ent ne?\n",
    "\n",
    "try:\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Read CSV files from the ZIP file into separate DataFrames\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "        # Read specific movie CSV files\n",
    "        with zip_file.open('Data/Movie_files/archive (2)/rotten_tomatoes_movies.csv') as csv_file:\n",
    "            rot_movies2 = pd.read_csv(io.TextIOWrapper(csv_file, 'utf-8'))\n",
    "\n",
    "        with zip_file.open('Data/Movie_files/archive (2)/rotten_tomatoes_movie_reviews.csv') as csv_file:\n",
    "            rot_critic2 = pd.read_csv(io.TextIOWrapper(csv_file, 'utf-8'))\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please provide the correct path to the ZIP file.\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset?select=rotten_tomatoes_critic_reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143258 entries, 0 to 143257\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    143258 non-null  object \n",
      " 1   title                 142891 non-null  object \n",
      " 2   audienceScore         73248 non-null   float64\n",
      " 3   tomatoMeter           33877 non-null   float64\n",
      " 4   rating                13991 non-null   object \n",
      " 5   ratingContents        13991 non-null   object \n",
      " 6   releaseDateTheaters   30773 non-null   object \n",
      " 7   releaseDateStreaming  79420 non-null   object \n",
      " 8   runtimeMinutes        129431 non-null  float64\n",
      " 9   genre                 132175 non-null  object \n",
      " 10  originalLanguage      129400 non-null  object \n",
      " 11  director              139041 non-null  object \n",
      " 12  writer                90116 non-null   object \n",
      " 13  boxOffice             14743 non-null   object \n",
      " 14  distributor           23001 non-null   object \n",
      " 15  soundMix              15917 non-null   object \n",
      "dtypes: float64(3), object(13)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "rot_movies2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_critic2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_rot2 = pd.merge(rot_critic2, rot_movies2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_rot2['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merged DataFrame:\")\n",
    "print(merged_rot2.shape)\n",
    "\n",
    "# Dropping rows with missing values\n",
    "merged_rot2 = merged_rot2.dropna()\n",
    "\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(merged_rot2.shape)  # Displaying the first few rows of the resulting DataFrame without missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_rot2 = merged_rot2.drop_duplicates(subset='title')\n",
    "\n",
    "print(\"\\nDataFrame after dropping duplicates based on 'title':\")\n",
    "print(merged_rot2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
